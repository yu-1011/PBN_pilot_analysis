{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca676e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import hail as hl\n",
    "import pandas as pd\n",
    "import gnomad\n",
    "from gnomad.resources.grch38 import gnomad\n",
    "#from gnomad.resources.grch38 import gnomad\n",
    "#import matplotlib.pyplot as plt # show() works!\n",
    "import pandas as pd\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ca460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/miniconda3/lib/python3.11/site-packages/hail/context.py:354: UserWarning:\n",
      "\n",
      "Using hl.init with a default_reference argument is deprecated. To set a default reference genome after initializing hail, call `hl.default_reference` with an argument to set the default reference genome.\n",
      "\n",
      "/opt/conda/miniconda3/lib/python3.11/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:43: UserWarning:\n",
      "\n",
      "Reading spark-defaults.conf to determine GCS requester pays configuration. This is deprecated. Please use `hailctl config set gcs_requester_pays/project` and `hailctl config set gcs_requester_pays/buckets`.\n",
      "\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook\n",
      "SPARKMONITOR_LISTENER: Port obtained from environment: 34687\n",
      "SPARKMONITOR_LISTENER: Application Started: application_1752605443147_0001 ...Start Time: 1752606194123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running on Apache Spark version 3.5.0\n",
      "SparkUI available at http://ychen-cnv-m.us-central1-a.c.pbn-analysis.internal:45779\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.135-034ef3e08116\n",
      "LOGGING: writing to /home/hail/hail-20250715-1903-0.2.135-034ef3e08116.log\n"
     ]
    }
   ],
   "source": [
    "hl.init(driver_cores=8,\n",
    "        worker_memory='standard',\n",
    "        default_reference='GRCh38',\n",
    "        tmp_dir='gs://pbn_pilot/proj-PBN/04_rare_SNPs/tmp/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689847f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in vcfs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=======================================>                 (16 + 7) / 23]\r"
     ]
    }
   ],
   "source": [
    "print(\"read in vcfs\")\n",
    "VCF_PATH = 'gs://fc-eb65ecd1-ad1b-4fed-a9cc-0f70571a9432/SSBC_BGE_pilot/*-SSBC-BGE-pilot.vcf.gz'\n",
    "vcfs = [entry['path'] for entry in hl.hadoop_ls(VCF_PATH)]\n",
    "mt = hl.import_vcf(vcfs, reference_genome='GRCh38', force_bgz=True, array_elements_required=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a31b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset pre-filtering\n",
      "filter multi alleles and split\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset pre-filtering\")\n",
    "print(\"filter multi alleles and split\")\n",
    "mt = hl.split_multi_hts(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca0c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = mt.repartition(2000, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d68e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vets(previously vqsr) filter\n"
     ]
    }
   ],
   "source": [
    "print(\"vets(previously vqsr) filter\")\n",
    "mt = mt.filter_rows(mt.filters == hl.empty_set(hl.tstr), keep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca895ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LCRs filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:04:03.519 Hail: INFO: Reading table without type imputation1) / 1]\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n"
     ]
    }
   ],
   "source": [
    "print(\"1. LCRs filter\")\n",
    "#LCR_PATH=\"gs://soyeon-sga/resources/LCRFromHengHg38.bed\"\n",
    "LCR_PATH=\"gs://gcp-public-data--gnomad/resources/grch38/lcr_intervals/LCRFromHengHg38.txt\"\n",
    "lcr_intervals = hl.import_locus_intervals(LCR_PATH, reference_genome='GRCh38', skip_invalid_intervals=True)\n",
    "mt = mt.filter_rows(hl.is_defined(lcr_intervals[mt.locus]), keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61df9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori=mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d648d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Telomeres_and_Centromeres filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:04:08.220 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "WARNING: An illegal reflective access operation has occurred======(23 + 4) / 23]\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.5.0.jar) to field java.lang.ref.Reference.referent\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2025-07-15 19:04:12.629 Hail: INFO: scanning VCF for sortedness...\n",
      "2025-07-15 19:04:18.366 Hail: INFO: Coerced sorted VCF - no additional import work to do\n",
      "2025-07-15 19:04:32.389 Hail: INFO: Coerced sorted dataset          (0 + 1) / 1]\n",
      "2025-07-15 19:04:33.010 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "[Stage 7:===(24 + 4) / 24][Stage 11:==(24 + 1) / 24][Stage 12:==(24 + 1) / 24]4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173918\n"
     ]
    }
   ],
   "source": [
    "print(\"2. Telomeres_and_Centromeres filter\")\n",
    "# cut -f1-3 hg38.telomeresAndMergedCentromeres.bed > hg38.telomeresAndMergedCentromeres_rmf4.bed\n",
    "# gsutil -m cp hg38.telomeresAndMergedCentromeres_rmf4.bed gs://soyeon-sga/resources/\n",
    "# Hail에서 GRCh38 기준으로 locus_interval()을 사용할 때 start 값이 1 이상이어야 하기 때문에 오류가 발생 0이면 1로 변환시킴\n",
    "TeloCentro_INTERVALS=\"gs://pbn_pilot/proj-PBN/misc/hg38.telomeresAndMergedCentromeres.rmf4_0to1.bed\"\n",
    "telocentro_intervals = hl.import_locus_intervals(TeloCentro_INTERVALS, reference_genome=\"GRCh38\", skip_invalid_intervals=True)\n",
    "mt = mt.filter_rows(hl.is_defined(telocentro_intervals[mt.locus]), keep=False)\n",
    "print(mt.count_rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b3c456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Segmentation duplicate filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:05:24.625 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "2025-07-15 19:05:39.282 Hail: INFO: Coerced sorted dataset\n",
      "2025-07-15 19:05:39.647 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2025-07-15 19:05:40.139 Hail: INFO: Coerced sorted dataset\n",
      "[Stage 7:===(24 + 4) / 24][Stage 11:==(24 + 1) / 24][Stage 12:==(24 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:===(24 + 4) / 24][Stage 11:==(24 + 1) / 24][Stage 12:==(24 + 1) / 24]\r"
     ]
    }
   ],
   "source": [
    "print(\"3. Segmentation duplicate filter\")\n",
    "SEGDUP_PATH=\"gs://gcp-public-data--gnomad/resources/grch38/seg_dup_intervals/GRCh38_segdups.bed\"\n",
    "segdup_intervals = hl.import_locus_intervals(SEGDUP_PATH, reference_genome='GRCh38', skip_invalid_intervals=True)\n",
    "mt = mt.filter_rows(hl.is_defined(segdup_intervals[mt.locus]), keep=False)\n",
    "print(mt.count_rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398675d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWIST Exome target region interval filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:06:46.315 Hail: INFO: Reading table without type imputation\n",
      "  Loading field 'f0' as type str (user-supplied)\n",
      "  Loading field 'f1' as type int32 (user-supplied)\n",
      "  Loading field 'f2' as type int32 (user-supplied)\n",
      "2025-07-15 19:07:00.143 Hail: INFO: Coerced sorted dataset\n",
      "2025-07-15 19:07:00.573 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2025-07-15 19:07:01.005 Hail: INFO: Coerced sorted dataset\n",
      "2025-07-15 19:07:01.914 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "[Stage 7:===(24 + 4) / 24][Stage 11:==(24 + 1) / 24][Stage 12:==(24 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:===(24 + 4) / 24][Stage 11:==(24 + 1) / 24][Stage 12:==(24 + 1) / 24]\r"
     ]
    }
   ],
   "source": [
    "print(\"TWIST Exome target region interval filter\")\n",
    "TARGET_INTERVALS=\"gs://pbn_pilot/proj-PBN/misc/Twist_Alliance_Clinical_Research_Exome_Covered_Targets_hg38-34.9MB.bed\"\n",
    "twist_intervals = hl.import_locus_intervals(TARGET_INTERVALS, reference_genome=\"GRCh38\", skip_invalid_intervals=True)\n",
    "mt = mt.filter_rows(hl.is_defined(twist_intervals[mt.locus]), keep=True)\n",
    "print(mt.count_rows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d89ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write Variant prefiltered mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:09:14.324 Hail: INFO: Coerced sorted dataset\n",
      "2025-07-15 19:09:14.649 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2025-07-15 19:09:15.160 Hail: INFO: Coerced sorted dataset\n",
      "2025-07-15 19:09:16.242 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2025-07-15 19:13:32.214 Hail: INFO: wrote matrix table with 155072 rows and 70 columns in 24 partitions to gs://pbn_pilot/proj-PBN/04_rare_SNPs/00_raw_data/01_Var_PreFilterQC.SCZ_BGE.mt\n",
      "[Stage 7:===(24 + 3) / 24][Stage 11:==(24 + 1) / 24][Stage 23:==(24 + 1) / 24]\r"
     ]
    }
   ],
   "source": [
    "print(\"write Variant prefiltered mt\")\n",
    "mt = mt.checkpoint('gs://pbn_pilot/proj-PBN/04_rare_SNPs/00_raw_data/01_Var_PreFilterQC.SCZ_BGE_20250715.mt', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f801fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}